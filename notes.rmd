---
title: 'Notes from *Introduction to Empirical Bayes*'
author: 'Peter Lukacs'
output:
    html_document:
        fig_width: 7
        fig_height: 5
        fig_align: center
---

```{r 'load-packages', echo=FALSE, warning=FALSE}
source('global.R')

theme_set(theme_light())
```

# I Empirical Bayes

## 2 The beta distribution

  + The beta distribution is a probability distribution with two parameters `alpha` and `beta`, constrained to between 0 and 1.

```{r 'beta-distro-plot', echo=FALSE}
beta_distro_params <- data.frame(a = c(1, 3, 20, 50), b = c(2, 3, 20, 10))
beta_distro_dt <- as.data.table(merge(beta_distro_params, x = seq(0, 1, 0.001), all = TRUE)) %>%
    .[, beta_density_value := dbeta(x, a, b), by = .(x, a, b)] %>%
    .[, Parameters := sprintf('a: %d, b: %d', a, b)]
ggplot(beta_distro_dt, aes(x, beta_density_value, color = Parameters)) +
    geom_line() +
    scale_y_continuous(name = 'Density of beta') +
    ggtitle('The beta distribution')
```

  + **Batting average** is an important baseball statistics which is calculated as the number of **hits (H)** divided by the number of **at-bats (AB)**. A player's batting average is always between 0 and 1 and can be represented with the beta distribution.

    \[Batting\ Average = \frac{H}{AB}\]

  + If a player starts out with a single or a strike out we wont't predict that his BA will be 1 or 0. This is because we've seen in the history that players tend to have a BA between .270 and .300, thus we have *prior expectations*.

    > The number of hits a player gets out of his at-bats is an example of a **binomial distribution**, which models a count of successes out of a total. Since it's a binomial, the best way to represent the prior expectations is with the beta distribution.

    > This is the Bayesian philosophy in a nutshell: we start with a prior distribution, see some evidence, then update to a **posterior** distribution.

  + Update the beta distribution this way:
    \[Beta(\alpha_0 + hits,\ \beta_0 + misses)\]

  + Below is an example of a player: first, our prior expectation about him is that he will have around .27 BA ($Beta(81, 219)$). After this, he hits the ball once out of one, so we update his posterior distribution to $Beta(82, 219)$, a tiny change. Later he will be up to bat 300 times and hits the ball a 100 times out of that, updating his beta to $Beta(181, 419)$.

```{r 'beta-distro-update-plot', echo=FALSE}
beta_distro_params <- data.frame(a = c(81, 82, 181), b = c(219, 219, 419))
beta_distro_dt <- as.data.table(merge(beta_distro_params, x = seq(0, .5, 0.001), all = TRUE)) %>%
    .[, beta_density_value := dbeta(x, a, b), by = .(x, a, b)] %>%
    .[, Parameters := sprintf('a: %d, b: %d', a, b)]
ggplot(beta_distro_dt, aes(x, beta_density_value, color = Parameters)) +
    geom_line() +
    scale_color_manual(values = c('dodgerblue', 'green3', 'violetred')) +
    scale_y_continuous(name = 'Density of beta') +
    ggtitle('The updated beta distribution') +
    labs(x = 'Batting Average') +
    theme_light()
```

  + **Posterior mean** is the expected value of the resulting beta distribution which we can use as our new estimate.
    \[E(Beta(\alpha, \beta)) = \frac{\alpha}{\alpha + \beta}\]
  + With the above example you can see that our posterior expectation is higher than our prior but lower than our expectation based on the actual inspected hits and misses:
    \[\frac{81}{81 + 219} < \frac{182}{182 + 419} < \frac{100}{100 + 200}\]

  + Imagine that our objective is to assess a player who we've seen hit 100/300. We can't take every person with the exact stats and see how they did historically but we can do a simulation:

```{r 'simulate-100/300-player'}
num_trials <- 10e6

# Take 10mm players whose betting average produces a Beta(81, 219)
# Then, simulate how well they'd do if they tried to hit the ball 300 times
simulations <- data_frame(
    true_average = rbeta(num_trials, 81, 219),
    hits = rbinom(num_trials, 300, true_average)
)

simulations

# Now filter for those who hit exactly 100/300 and then plot their true average distribution
hit_100 <- simulations %>%
    filter(hits == 100)
```

```{r 'hit-100-plot', echo=FALSE, warning=FALSE}
dens <- function(x) dbeta(x, 81 + 100, 219 + 200)

ggplot(hit_100, aes(true_average)) +
    geom_histogram(aes(y = ..density..)) +
    stat_function(color = 'red', fun = dens) +
    labs(x = 'Batting average of players who got 100 H / 300 AB')
```

  + The median of the histogram (0.3) is our posterior estimate: we believe that a player with history of 100/300 is likely to have a BA of 0.3.
  + The histogram of the 100/300 batters and the well-fitted Beta density plot (red) confirms the math about the conjugate prior: you can calculate the posterior estimate without running a simulation.
  + See below cases where players hit 60, 80 or 100 times based on the simulation

```{r 'hit-60-80-100-plot', echo=FALSE, warning=FALSE}
simulations %>%
    filter(hits %in% c(60, 80, 100)) %>%
    ggplot(aes(true_average, color = factor(hits))) +
        geom_density() +
        labs(x = 'Batting average of players who got 60, 80, 100 H / 300 AB',
                 color = 'H')
```

## 3 Empirical Bayes estimation

  + This method will fit a beta distribution on all observations which is then used to omprove each individually. This way we won't need to have prior expectations

#### 3.1 Setup: the Lahman baseball dataset

  + From now on we'll be working on real data from the *Lahman baseball dataset*

```{r 'lahmna-dataset', warning=FALSE}
# Filter out pitchers (b/c they are unusually weak batters)
career <- Batting %>%
    filter(AB > 0) %>%
    anti_join(Pitching, by = 'playerID') %>%
    group_by(playerID)  %>%
    summarize(H = sum(H), AB = sum(AB)) %>%
    mutate(average = H / AB)

# Include names
career  <- Master %>%
    tibble::as_tibble() %>%
    select(playerID, nameFirst, nameLast) %>%
    unite(name, nameFirst, nameLast, sep = ' ') %>%
    inner_join(career, by = 'playerID')

career
```

The following tables show you that simply using the average column won't get us the best or worst players

```{r 'best-worst-average', echo=FALSE, warning=FALSE}
career %>% top_n(5, average)
career %>% top_n(-5, average)
```

#### 3.2 Step 1: Estimate a prior from all the data

  + It's sometimes not appropriate to use the data we analyze to calculate the priors but with the amount of data we have currenltly it's fine, since the estimate won't depend much on any individual.
  + The below histogram shows that a beta distribution is a pretty appropriate choice for our data

```{r 'histogram-of-BAs', echo=FALSE, warning=FALSE}
career %>%
    filter(AB > 500) %>%
    ggplot(aes(average)) +
        geom_histogram(bins = 50)
```

    + Now we would need to fit the follwing model to find the $\alpha_0$ and $\beta_0$ *hyper-parameters*:

    \[ X \sim Beta(\alpha_0, \beta_0) \]

```{r 'maximum-likelihood'}
career_filtered <- career %>%
    filter(AB > 500)

log_likelihood <- function(alpha, beta) {
    x <- career_filtered$H
    total <- career_filtered$AB
    -sum(VGAM::dbetabinom.ab(x, total, alpha, beta, log = TRUE))
}

max_likelihood_estimation <- mle(log_likelihood, start = list(alpha = 1, beta = 10), method = 'L-BFGS-B',
                                 lower = c(0.0001, .1))

ab <- coef(max_likelihood_estimation)

alpha0 <- ab[1]
beta0 <- ab[2]

dens <- function(x) dbeta(x, alpha0, beta0)

ggplot(career_filtered, aes(average)) +
    geom_histogram(aes(y = ..density..), bins = 50) +
    stat_function(color = 'red', fun = dens, size = 2) +
    labs(title = 'Histogram of BAs and the maximum likelihood fitted beta density distribution',
         x = 'BA',
         y = 'density')
```

  + The maximum likelihood model came up with $\alpha_0 =$ `r round(alpha0, 2)` and $\beta_0 =$ `r round(beta0, 2)`. We can see from the above plot that it fits the actual data pretty well.

#### 3.3 Step 2: Use that distribution as a prior for each individual estimate

  + Now we can update our data with our priors like so:

\[\frac{H + \alpha_0}{AB + \alpha_0 + \beta_0}\]

```{r 'empirical-bayes-estimate'}
career_eb <- career %>%
    mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0))
```

#### 3.4 Results

  + And we're able to ask who is the best/worst player:

```{r 'best-wors-emipircal-bayes-estimate', echo = FALSE}
career_eb %>% top_n(5, eb_estimate)
career_eb %>% top_n(-5, eb_estimate)
```

    + See below how empirical Bayes changed our estimate of batting averages:

```{r 'empirical-vs-bayesian-batting-averages', echo = FALSE}
ggplot(career_eb, aes(average, eb_estimate, color = AB)) +
    geom_point() +
    geom_hline(yintercept = alpha0 / (alpha0 + beta0), color = 'red', lty = 2) +
    geom_abline(color = 'red') +
    scale_colour_gradient(trans = 'log', breaks = 10 ^ (1:5)) +
    xlab('Batting average') +
    ylab('Empirical Bayes batting average')
```

  + The horizontal dashed lines shows $\frac{\alpha_0}{\alpha_0 + \beta_0}$. That would be our Bayesian estimate if someone would have $AB = H = 0$. The red diagonal line shows $x = y$. Points near that line are the brightest, because the more evidence we have, the less we distort (update) the average with the priors.

  > This process is often called **shrinkage**: the process of moving all our estimates towards the averge. Or in other words: *Extraordinary outliers require extraordinary evidence.*

## 4. Credible Intervals

  > Empirical Bayes gives us a reliable estimate but sometimes we want to know more than just our "best guess", and instead wish to know how much uncertainty is present in our point estimate

  + The problem with binomial proportion confidence interval is that is desn't use prior knowledge. As a result for betters with short history it would give a huge confidence range

#### 4.1 Setup [intentionally left out]

#### 4.2 Posterior distribution

  + Apart from calculating point estimates from priors and evidence from players we can also calculate an updated personal Beta distribution for each player. What we are looking for is $\alpha_1 = \alpha_0 + H$ and $\beta_1 = \beta0 + AB - H$

```{r 'posterior-distributions'}
career_eb <- career_eb %>%
    mutate(alpha1 = alpha0 + H,
           beta1 = beta0 + AB - H)
```

```{r 'posterior-distributions-plot', echo = FALSE}

yankee_1998 <- c("brosisc01", "jeterde01", "knoblch01", "martiti02",
                 "posadjo01", "strawda01", "willibe02")

yankee_1998_career <- career_eb %>%
    filter(playerID %in% yankee_1998)

yankee_beta <- yankee_1998_career %>%
    crossing(x = seq(.18, .33, .0002)) %>%
    ungroup() %>%
    mutate(density = dbeta(x, alpha1, beta1))

ggplot(yankee_beta, aes(x, density, color = name)) +
    geom_line() +
    stat_function(fun = function(x) dbeta(x, alpha0, beta0),
                lty = 2, color = "black") +
    labs(x = "Batting average",
         color = "Player")
```

#### 4.3 Credible intervals

  + These personal distributions are hard to interpret. We rather have information on how much (e.g. 95%) of the posterior distribution lies within a particular region. A credible interval for Derek Jeter is shown below, while 95% credible intervals for the other players under that.

```{r 'jeter-credible-interval'}
jeter <- yankee_beta %>%
    filter(name == "Derek Jeter")

jeter_low <- qbeta(.025, jeter$alpha1[1], jeter$beta1[1])
jeter_high <- qbeta(.975, jeter$alpha1[1], jeter$beta1[1])

jeter %>%
    ggplot(aes(x, density)) +
        geom_line() +
        geom_ribbon(aes(ymin = 0, ymax = density), data = setDT(jeter)[x > jeter_low & x < jeter_high],
                    alpha = .25, fill = "red") +
        stat_function(fun = function(x) dbeta(x, alpha0, beta0),
                    lty = 2, color = "black") +
        geom_errorbarh(aes(xmin = jeter_low, xmax = jeter_high, y = 0), height = 3.5, color = "red") +
        xlim(.18, .34) +
        labs(title = 'The posterior beta distribution for Derek Jeter',
             subtitle = '3465 H / 11195 AB, with the 95% credible interval')
```


```{r 'add-credible-intervals'}
yankee_1998_career <- yankee_1998_career %>%
    mutate(low  = qbeta(.025, alpha1, beta1),
           high = qbeta(.975, alpha1, beta1))
```

```{r 'credible-interval-table', echo = FALSE}
yankee_1998_career %>%
    dplyr::select(-playerID, -alpha1, -beta1, -eb_estimate) %>%
    knitr::kable()
```

```{r 'credible-interval-for-the-rest-of-the-players'}
yankee_1998_career %>%
    mutate(name = reorder(name, eb_estimate)) %>%
    ggplot(aes(eb_estimate, name)) +
        geom_point() +
        geom_errorbarh(aes(xmin = low, xmax = high)) +
        geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = "red", lty = 2) +
        xlab("Estimated batting average (w/ 95% interval)") +
        ylab("Player")
```

#### 4.4 Credible intervals (CrI) and confidence intervals (CoI)

  + There is a philosophical and a practical difference between the above two:
      * Philosophical: The frequentist method (CoI) assumes that the parameter that we are estimating is an exact number and that the CoI will include that number X% of the times. The Bayesian method assumes that the parameter is picked from a distribution and the CrI describes this distribution.
      * Practical: While the frequentist method doesn't use the information of other observations, the Bayesian method does so by calculating the priors.
  + Frequentist and Bayesian intervals and estimates are becoming identical once we have many enough observations (see below)

```{r 'credible-interval-vs-confidence-interval-plot', echo = FALSE}
career_eb <- career_eb %>%
    mutate(low = qbeta(.025, alpha1, beta1),
           high = qbeta(.975, alpha1, beta1))

set.seed(2015)

some <- career_eb %>%
    sample_n(20) %>%
    mutate(name = paste0(name, " (", H, "/", AB, ")"))

frequentist <- some %>%
    group_by(playerID, name, AB) %>%
    do(broom::tidy(binom.test(.$H, .$AB))) %>%
    ungroup() %>%
    dplyr::select(playerID, name, estimate, low = conf.low, high = conf.high) %>%
    mutate(method = "Confidence")

bayesian <- some %>%
      dplyr::select(playerID, name, AB, estimate = eb_estimate,
                    low = low, high = high) %>%
      mutate(method = "Credible")

combined <- bind_rows(frequentist, bayesian)

combined %>%
    mutate(name = reorder(name, -AB, na.rm = TRUE)) %>%
    ggplot(aes(estimate, name, color = method, group = method)) +
        geom_point() +
        geom_errorbarh(aes(xmin = low, xmax = high)) +
        geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = "red", lty = 2) +
        xlab("Estimated batting average") +
        ylab("Player") +
    labs(color = "")
```

